# 3.1 Churn Prediction Project

Imagine you are a telecom company, with many customers.
- Naturally, some clients are not happy with your services, and may change providers
- This is called **churn**. Want to predict clients that may churn
    - We will assign some score [0, 1] that is the probability a customer may churn
        - E.g. customer A has 0.2, B 0.3, C 0.4, D 0.45, E 0.85
- If a customer is about to churn, we may want to send them an email or promotion 
- Needs to be accurate; losing money if we send promotions to clients who are going to stay anyway

## Binary Classification
Will be using binary classification for this project.
- *g*(*x<sub>i</sub>*) ≈ *y<sub>i</sub>*
    - *x<sub>i</sub>* could be a feature vector for a customer
    - *y<sub>i</sub>* could be a target for said customer
- *y<sub>i</sub>* ∈ {0, 1}
    - 0 is a negative example; no **churn** or no spam
    - 1 is a positive example; it is **churn** or it is spam
- The result of *g*(*x<sub>i</sub>*) is the likelihood the customer *i* will churn
    - E.g. Take customer from last month
        - If they left, give them a value of 1. Otherwise, 0
            - This becomes *y*
        - The information about the customer becomes *X*
            - Customer information
            - How much they pay
            - What they pay for
            - What kind of contract they are on
- Want to build model using historical data and score them all with some likelihood of churning
    - Target those with a high score with promotional emails

## Dataset
For this project, we used a [Kaggle dataset](https://www.kaggle.com/blastchar/telco-customer-churn).
- Features like:
    - Partners
    - Dependents
    - How long they are with companies
- Notably it has a churn field

# Unit 3 Sections:
1. Download
2. Prepare data
3. Set up validation framework (Scikit-learn)
4. EDA (with target variable)
5. Feature importance: Churn rate and risk ratio
6. Feature Importance: Mutual Information
7. Feature Importance: Correlation
8. One-hot Encoding
9. Logistic Regression
10. Training Logistic Regresion with Scikit-Learn
11. Model Interpretation
12. Using the Model
13. Summary