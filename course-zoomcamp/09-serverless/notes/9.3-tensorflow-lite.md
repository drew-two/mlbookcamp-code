# 9.3 - TensorFlow Lite

## Why TensorFlow Lite
Why do we care about size?
- Historical reasons - AWS lambda used to have 50 MB zip size
    - Now this is up to 10GB (for docker images)
- Large image not as convenient
    - \$ for storage (though not a lot)
    - Slow init time you still have to pay for
- Slower to import, bigger RAM footprint

Faster for inference
When you do `model.predict(*X*)`
- ONLY used for inference (all TF-Lite can do)

## Getting old model
Can get it from course Github [releases](https://github.com/alexeygrigorev/mlbookcamp-code/releases)

See [Notebook](../notebook.ipynb)