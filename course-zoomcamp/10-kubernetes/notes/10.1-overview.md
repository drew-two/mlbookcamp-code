# 10.1 - Overview

Recall: Same fashion classification scenario from last section.

![Overview](../images/10.1-overview.png)

Will use TF-Serving to serve model
- Made by Tensorflow team just for serving Tensorflow models
- Library written in C++ (very efficient) just for inference
    - Takes *X* matrix as input
    - Returns one-hot array

Need web server to send URL of image from website to TF-serving instance
- Need gateway to preprocess images and interpret results
    - TF-serving use gRPC for communication
- Will use Flask for the gateway

All of this takes places in Kubernetes
- Helps separate resourcs using GPU only for TF-serving instance
    - Gateway needs to serve website, download images, prepare output. Does not need GPU
    - GPUs are generally expensive
- Allows us to scale these independently
- Already have code (Script and Dockerfile) for gateway
    - Will focus on making the services and testing

## Overview
1. Overview (this)
2. Tensorflow Serving
    - Saved model format
    - Running from Docker
    - Invoking with Jupyter
3. Creating pre-processing service
    - Convert notebook to script
    - Wrap script with Flask
4. Running everything locally with Docker-compose
    - Preparing images
    - Installing docker-compose
    - Running/testing
5. Intro to Kubernetes
    - Anatomy of cluster
6. Deploying simple service to Kubernetes
    - Intallig kubectl
    - Setting up local cluster with **Kind**
    - Creating deployment/service
7. Deploying TF models to Kubernetes
    - Deploying TF-Serving model
    - Deploying the Gateway
    - Testing the service
8. Deploying to EKS
    - Creating EKS cluster on AWS
    - Publishing image to ECR
    - Configuring kubectl
9. Summary