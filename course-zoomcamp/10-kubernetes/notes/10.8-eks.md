# 10.8 - Deploying to EKS

[AWS EKS](https://aws.amazon.com/eks/) is Amazon's managed Kubernetes solution.
- Can deploy Kubernetes with AWS's tools to multiple different AWS services or local servers
- Supports EC2 GPU instances for ML training jobs
- Specific command line tool `eksctl` to control multiple clusters

## Creating EKS cluster
Go to [AWS EKS](https://console.aws.amazon.com/eks/)
- We will use [eksctl CLI tool](https://docs.aws.amazon.com/eks/latest/userguide/eksctl.html) to create this
- Can create EKS cluster on AWS with:
    - `eksctl create cluster --name zoomcamp-eks`
- But instead we wil make the cluster with a config file
    - Make [eks-config.yaml](../kube-config/eks-config.yaml)
    - Copy the contents from the eksctl [main page](https://eksctl.io/)
        - Change name to `mlzoomcamp-eks`
        - Adjust region
        - Remove first nodegroup and rename second to `ng-1`
            - Uses `m5.xlarge` - 5 vCPU and 16GB RAM
        - Change to 1 machine
    - Recall we talked about nodes - nodegroups are a group with the same configuration/type of instance etc
        - May want to deploy model to nodegroups with GPUS and gateway to nodegroups with just CPUs
- Create cluster with `eksctl create cluster -f eks-config.yaml`

## Pushing docker images
In the meantime let's look at our deployments.
- We need to push our local images to ECR
    - Need to publically available through docker hub or available in ECR
    - We will follow same steps as week 9
- Run `aws ecr create-repository --repository-name mlzoomcamp-images`
    - Get repository URI. Can do the same things as last time to recreate repository URL
    - Get the two images we need and add as variables. Docker tag them with these
        - E.g. `docker tag ${local_name} ${remote_name}
- Now we need to log into ECR
    - `$(aws ecr get-login --no-include-email)`
    - Not the safest but should be fine here
- Add `docker push ${model-tag}` to the script and run it

Now we need to get the URI of these images and put them in our deployment configurations
- Run `echo ${MODEL_REMOTE}` and `echo ${GATEWAY_REMOTE}` to get these
- Add these to the respective deployment files

## Deploying to the cluster
Check that you are connected to the EKS cluster. 
- Run `kubectl get nodes`. Should see something like:
    ```
    $ kubectl get nodes
    NAME                                          STATUS   ROLES    AGE   VERSION
    ip-192-168-81-78.us-east-2.compute.internal   Ready    <none>   73m   v1.23.13-eks-fb459a0
    ```
- Apply the 4 yaml files to the cluster
    - Apply model deployment and service yaml files to cluster
        - Check the pods and services in kubectl to verify
        - Port forward with `kubectl port-forward service/tf-serving-clothing-model 8500:8500`
    - Test with [gateway.py](../gateway.py)
        - Should work after a few seconds
    - Apply gateway deployment and service yaml files
        - Check the pods and services in kubectl to verify
        - Service should give you an External IP - a long URL
        - Use telnet on port 80 to see if something is running
            - Might take a second after applying to see something
        - Port forward with `kubectl port-forward service/gateway 8080:80`
            - Test with [test.py](../test.py) going to 'http://localhost:8080/predict'
            - Should work
- Take the service URL and put it in [test.py](../test.py)
    - Change the url variable with the new URL 
        - Add `http://` and `/predict`
        - Test. Should work
- Go to [EC2](https://console.aws.amazon.com/ec2/)
    - Under Instances you can see the EC2 used for EKS
    - Under Load Balancer you can see the elastic load balancer for service/gateway
- This method opens URL to the outside world
    - Probably do not want to do this - want to restrict
    - Outside the scope of this course

Delete the EKS cluster. Will be unused and still charge us
- Also deletes the EC3 instances and load balancer
- Run `eksctl delete cluster --name mlzoomcamp-eks`

## Recap
1. Created EKS cluster with eksctl
2. Pushed cluster docker images to ECR
3. Adjusted configuration to get images from ECR
4. Apply yaml files with kubectl (eksctl handles kubectl config)