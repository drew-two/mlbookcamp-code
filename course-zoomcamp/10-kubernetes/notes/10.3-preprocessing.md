# 10.3 - Creating a Pre-Processing Service

## Converting script
Convert jupyter notebook to Python script
- Use `jupyter nbconvert --to script tf-serving-connect.ipynb`
- Rename script to [gateway.py]
- Remove lines above imports and the Jupyter cell lines
- Cleanup and methodize
- Put URL in main, predict, and print output

Try testing script
- Should work

## Making Flask application
Can check from [fifth section](../../05-deployment/code/predict.py)
- Copy in imports
- Copy in app info and function decorator
    - Add function `predict_endpoint()`
- Adjust main to start the Flask app

Test the application
- Create test file. Can copy from [ninth section](../../09-serverless/code/test.py)
    - Just change URL
- Run from command line. Should work

## Creating Pipenv
Note we have two services now: TF-serving and gateway app.

Now we will create a Pipenv for later
- Run `pipenv install grcpio==1.42.0 flask gunicorn ^Cras-image-helper`
- Note we are not installing tensorflow or tensorflow-serving
    - Only use Tensorflow in the main app once
        - In `np_to_protobuf()` we load the entire TF just to convert
    - Even tensorflow-cpu is pretty large
    - Alexey created a [package](https://github.com/alexeygrigorev/tensorflow-protobuf) to fix this
        - Pulls the code from the TF library but is just protobuf conversion
        - Requires some more code but much less filesize
    - Run `pipenv install tensorflow-protobuf==2.7.0`
- Add a new file [`proto.py`](./proto.py)
    - Copy code from example on the Github
    - Note that we still import `tensorflow.core.framework`
        - The package only has the `tensor_pb2, tensor_shape_pb2, types_pb2` subclasses
    - Import the entire function `np_to_protobuf()` from [`proto.py`](./proto.py) instead
- Run gateway.py again
    - Should work. Notice there are no Tensorflow CUDA warnings.
    - This is because none of that code related to prediction or GPU is loaded
