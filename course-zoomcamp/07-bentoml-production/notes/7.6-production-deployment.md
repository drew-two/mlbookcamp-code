#  7.6 - Bento Production Deployment

Deploying to AWS via ECS
- GCP/Azure have analogs
- Easy way to deploy and scale containers out-of-the-box

Take a look at [service.py](../service.py)
- Want the model with batching (`async` and `await`)
- Build this bento with `bentoml build`
    - Get the tag e.g. `Successfully built Bento(tag="tag_name:tag_version")`
    - (We got credit_risk_classifier:ewmcxrdgyw4msaav)
- Containerize with `bentoml containerize <tag_name>:tag_version`
    - Also add flag `--platform=linux/amd64` if you are on another platform (needs Docker running)

## AWS overview
- Typical cloud provider
- Can use free tier - needs credit card
    - Make sure to turn things off after you're done
- Go to [AWS ECR](https://us-east-2.console.aws.amazon.com/ecr/home) and create ECR repository
    - Set it to private, name it something appropriate. Everything else is fine. Create.
    - Click new repo in list and check `View Push Commands` at the top
        - This is how to add containers to your registry
        - Uses AWS CLI. Check [Getting Started with Amazon ECR](http://docs.aws.amazon.com/AmazonECR/latest/userguide/getting-started-cli.html) if need be
            - Needs access keys and secret keys set
                - Do NOT do this in prod
            - Set up keys in `aws configure` in command line or `export AWS_PROFILE=<profile_name>`
- Check local images with `docker images`
    - Tag using `docker tag <repository_name>:<tag> <ecr_repo_url>:<tag>` as in Step 3 of `View Push Commands`
        - Repo URL should be of the form `<aws_account_#>.dkr.ecr.<amazon_region>.amazonaws.com/<repo_name>:latest`
    - Now push from the new tag to ECR: `docker push <ecr_tag>`

## ECS Cluster
Go to [AWS ECS](https://us-east-2.console.aws.amazon.com/ecs/home)
- This is just a simple way to deploy a container directly. Not necessarily right or better
- Go to ECS > Clusters > Create Cluster > Networking only
    - We use Fargate because this makes the most sense for a new AWS user
        - No GPU however. Need EC2 to do that but need to upgrade quota to do so
    - Fargate is the AWS managed service for elastic compute
- Add Cluster name, use default option. Then, select `Create`.
    - Check out the [AWS docs](https://docs.aws.amazon.com/IAM/latest/UserGuide/using-service-linked-roles.html#create-service-linked-role) if you get an error here

## ECS Task
Now create an ECS Task Definition (ECS > Task Definitions in left bar)
- Hit `Create new Task Definition` > FARGATE > `Next Step`
- Name the task. Choose *Linux* for `Operating system family`
    - For `Task memory (GB)` choose *0.5GB*
    - For `Task CPU (vCPU)` choose *0.25 vCPU*
    - This keeps us in free tier
- Now for `Add container`, choose container name
    - Set the latest image from the ECR repo we made. Get the *URI*
        - Paste this under `Image` in for the Task definition
    - Bump up `Memory Limits (MiB)`: *Soft limit* to *256*
        - Want this as inference is generally CPU bound and may need to burst above soft limit
        - Would want to add *Hard Limit* for larger models
    - Set `Port mappings` as that was what we use for the Bento
    - Use default settings and hit `Create`.

Go back to the cluster (ECS > Clusters > `credit-risk-classifier-cluster`)
- Click on the cluster, go to `Tasks` and hit `Run new Task`
    - Select `Launch type`: *FARGATE*
    - Select `Operating system family`: *Linux*
    - Set `Task Definition` as the one we just made. Use latest Revision
    - Leave `Number of tasks` and `Task Group` alone
    - Set `Cluster VPC` to an apporiate one you have
    - Set `Subnets` using any public one you have fine for test
    - Edit `Security groups` 
        - Add TCP port 3000
    - Make sure `Auto-assign public IP` is *ENABLED*
    - Hit `Run Task`

Can see the task running now
- Click on the task. Hit refresh if need be
- Can see metadata - where it is running, networking etc
- Use the Public IP at port 3000 to see the Swagger page in your browser
    - E.g. `Public IP`: xxx.xxx.xxx.xxx, so http://xxx.xxx.xxx.xxx:3000/

BentoML can also deploy to SageMaker and use GPUs
- Can also be pushed to an S3 bucket

# Summary
- Deploy service.py with bentofile.yaml
    - Run `bentoml build` in the same directory or with the path of the bentofile
- Containerize bento with `bentoml containerize <tag_name>:tag_version [--platform=linux/amd64]`
- To tag for an AWS ECR repo, first get the image tag with `docker images`
    - Then run `docker tag <repository_name>:<tag> <ecr_repo_url>:<tag>`
    - ECR Repo tag can be anything
- To push to ECR run `docker push <ecr_tag>`, where the tag is the URL and tag you just used
- Go to [AWS ECS](https://us-east-2.console.aws.amazon.com/ecs/home) > Clusters > `Create Cluster` to make a new cluster
- Create Task to run this container under ECS > Task Definitions > `Create new Task Definition`
- Launch task from ECS > Clusters > *new cluster* > `Tasks` > `Run new Task`
    - Can access from Public IP for this task