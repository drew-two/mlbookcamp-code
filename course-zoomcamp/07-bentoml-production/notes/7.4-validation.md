# 7.4 - Sending, Receiving and Validating Data

Use [code](../code/service.py) and recall dummy data:
```
{
    "seniority": 3,
    "home": "owner",
    "time": 36,
    "age": 26,
    "marital": "single",
    "records": "no",
    "job": "freelance",
    "expenses": 35,
    "income": 0.0,
    "assets": 60000.0,
    "debt": 3000.0,
    "amount": 800,
    "price": 1000
}
```
- This is just raw JSON. We can send it to the backend any way we want
- What if we start messing up the data?
    - Usually happens by accident all the time in production in testing.
- **PROBLEM**: It returns output that seems like it was given valid input
    - This is worse as we do not see the error or why it worked.
- Thus we use a **pydantic schema**

Create class `CreditApplication(BaseModel):`
- This pulls from pydantic.BaseModel `from pydantic import BaseModel`
- Will use this to map all the individual fields from the JSON. Identical object to JSON we will be receiving
    - E.g. 
    ```
        seniority: int
        home: str
        time: int 
        ...
    ```
    - MUST map 1:1 to fields we want.
    - Though, if we make mistakes, the errors are fairly descriptive
- To see if our data is validated, we can set `pydantic_model` under the input JSON for the bentoml service API:
    `@svc.api(input=JSON(pydantic_model=CreditApplication), output=JSON())`
- Now, when we send data that does not match this schema, it fails
    - This actually fails because we did not change the definition of function `classify` to check for class `CreditApplication` instead of JSON
        - We can drop this in:
            ```
            async def classify(credit_application):
            application_data = credit_application.dict()
            ```
    - Now, testing should work

- Try messing with the JSON now:
    - Removing field `marital`:
        - Fails:
        ```
        "BentoService error handling API request: Invalid JSON input received: 1 validation error for CreditApplication\nmarital\n  field required (type=value_error.missing)"
        ```
    - Use `int` instead of `str` for `marital`:
        - This actually works cause JSON encodes everything as strings
    - Use `str` instead of `int` for `time`:
        - Fails:
        ```
        "BentoService error handling API request: Invalid JSON input received: 1 validation error for CreditApplication\ntime\n  value is not a valid integer (type=type_error.integer)"
        ```
- Can see full Pydantic [documentation](https://pydantic-docs.helpmanual.io/)

Let's look at some other types of data we can send/receive:
- E.g. Getting CSV file type from the last module
    - Say you are getting this line-by-line in an array
    - Can use Ndarray `from bentoml.io import NumpyNdarray`
    - This is a helper type that casts arrays into NumPy array
        - Can adjust svc.api such that: `@svc.api(input=NumpyNdarray(), output=JSON())`
        - Adjust function definition to `async def classify(vector):`
    - Can now send array like [[x.xe+01, x.xe+01, ... x.xe+01,]]
- In we have situations like this the data is a little more opaque
    - Have no idea if input data is like how we expect it to be and if output is useful
- Need some way to evaluate ndarray

Some ways to validate shape of Ndarray
- Can specify `shape` of array:
    - `input=NumpyNdarray(shape=(-1,29), enforce_shape=True)`
    - This shows there are 29 values and each value can be arbitrarily long, and enforce shape
    - If we try removing some values:
        - Get error:
        ```
        "BentoService error handling API request: NumpyNdarray: Expecting ndarray of shape \"(-1, 29)\", but \"(1, 2)\" was received."
        ```
- Can specify `dtype` of array
    - `input=NumpyNdarray(shape=(-1,29), dtype=np.float32, enforce_dtype=True, enforce_shape=True)`
    - Specifies only 32-bit floats and enforces
