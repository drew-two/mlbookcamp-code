# 7.8 Summary

## Sections
1. Overview
2. Building a prediction service
    - Used notebook from module 6
    - Save model and dictionary vectorizer with BentoML
    - Created [service.py](../service.py) to serve model with BentoML
    - Built this with `bentoml build` and [bentofile.yaml](../bentofile.yaml)
3. Deployed the service
    - Deployed from bento
    - Took at look what metadata BentoML automatically stores
    - Containerized with just `bentoml containerize`
4. Sending, Receiving and Validating Data
    - Created pydantic schema for CreditApplication class for all the fields in the JSON data
    - Applied it to the JSON input for the service API fufnction
    - Tested validation with JSON or NumPy arrays
5. High Performance Serving
    - Used `async` and `await` to parallelize better
    - Used Locust to test traffic
    - Explored traditional scaling process and saw why it doesn't work for ML
    - Explored batching options for ML and why it works better
6. Bento Production Deployment
    - Created AWS cluster with ECS
    - Pushed container image to ECR
    - Deployed image to ECS and usd public IP
7. (Optional) Deploying Stable Diffusion
    - Advanced deployment turning pretrained model into bento
    - Deployed to ECS
    - Tested Stable Diffusion 