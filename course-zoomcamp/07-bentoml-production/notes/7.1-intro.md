# BentoML Intro/Overview

- Tim, Head of Product at BentoML
- Data startups most of his career
- Started in development as BE
- Now mostly in product, talking with users and planning videos like this.

## Review
- In module 6, we made a credit risk prediction model
    - Cleaned up data
    - Developed features
    - Tried multiple models and chose the best
- Real-life use case, typically what you start with and you can expand with other types of data as well

- Now where do we go from here? How do we get this in the hands of real people applying for credit?
- Most people applying for credit online. Lenders usually have a primary website where this takes place
    - Turnaround used to take days, but now it can be almost instantaneous
    - How do we connect people applying on the website with the model?

- People who are applying on the website are filling out their data.
    - Probably filling in the data the model was trained on.

- In module 5, we pickled the model, wrapped it in a Flask app and served an API endpoint
    - In the real world there is much more we need to prepare for production-level traffic

## Goal of this Module
- Build and deploy an ML service
- Customize your service to fit your use case
- Make sure your service is _production ready_

What is production ready?
1. Scalability
2. Operational efficiency
    - Being able to maintain service automatically - does not need someone always watching
3. Repeatability (CI/CD)
    - Making sure you can update automatically or build a similar service without redoing everything
4. Flexibility
    - Escape hatch; if you ever need to react to late-stage requirements changes or unforeseen issues in productions
5. Resiliency
    - Even if service completely fails, should be able to go back to previous state
6. Easy to use -ity
    - Good frameworks should be easy-to-use

- Don't worry about all of this the first day, getting the service deployed at all is the first step.

## What is a Bento?
- Japanese home-packed portable meal, often for lunch
    - Different courses of the meal are separated in the box
- How is this like ML services?
    - An ML service requres:
        - Code
        - Model(s)
        - Data & Processing
        - Dependencies
        - Configuration
        - Deploy Logic
        - Etc...
    - The point is, a Bento is the abstraction for packing all these into one deployable (portable) unit
- BentoML makes it easy to **create** and **package** service for production

## Overview

1. Introduction (this page)
2. Building a prediction service
3. Deploying a prediction service
4. Anatomy of a BentoML service
5. Customizing Bentos
6. BentoML Production Deployment
7. High Performance serving
8. Customer Runner/framework