{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this homework, we'll deploy the dino or dragon model we trained in the [previous homework](../09-serverless/homework.md).\n",
    "\n",
    "Download the model from here:\n",
    "\n",
    "https://github.com/SVizor42/ML_Zoomcamp/releases/download/dino-dragon-model/dino_dragon_10_0.899.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘dino_dragon_10_0.899.h5’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://github.com/SVizor42/ML_Zoomcamp/releases/download/dino-dragon-model/dino_dragon_10_0.899.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ IMPORTING LIBRARIES AND DEPENDENCIES:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Now convert this model from Keras to TF-Lite format.\n",
    "\n",
    "What's the size of the **converted** model?\n",
    "\n",
    "* 21 Mb\n",
    "* 43 Mb\n",
    "* 80 Mb\n",
    "* 164 Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 00:33:09.684829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-29 00:33:09.693593: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:\n",
      "2022-11-29 00:33:09.693624: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-29 00:33:09.694365: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"dino_dragon_10_0.899.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 00:33:10.419267: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpl65_cxp8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 00:33:11.037025: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-11-29 00:33:11.037069: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2022-11-29 00:33:11.037646: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpl65_cxp8\n",
      "2022-11-29 00:33:11.038432: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-11-29 00:33:11.038445: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmpl65_cxp8\n",
      "2022-11-29 00:33:11.041979: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-11-29 00:33:11.098384: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpl65_cxp8\n",
      "2022-11-29 00:33:11.107200: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 69557 microseconds.\n",
      "2022-11-29 00:33:11.118360: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model) # path to the saved model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('dino-dragon-model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 129M\n",
      "-rwxrwxrwx 1 andre andre  269 Nov 29 00:22 Dockerfile\n",
      "-rwxrwxrwx 1 andre andre 368K Mar  4  2016 Smaug.jpg\n",
      "drwxrwxrwx 1 andre andre 4.0K Nov 29 00:16 __pycache__\n",
      "-rwxrwxrwx 1 andre andre  43M Nov 29 00:33 dino-dragon-model.tflite\n",
      "-rwxrwxrwx 1 andre andre  86M Nov 19 13:23 dino_dragon_10_0.899.h5\n",
      "-rwxrwxrwx 1 andre andre  18K Nov 29 00:32 homework.ipynb\n",
      "-rwxrwxrwx 1 andre andre 4.8K Nov 25 18:07 homework.md\n",
      "-rwxrwxrwx 1 andre andre 1.2K Nov 29 00:25 lambda_function.py\n",
      "-rwxrwxrwx 1 andre andre  220 Nov 29 00:30 push_to_ecr.sh\n",
      "-rwxrwxrwx 1 andre andre  242 Nov 29 00:19 test.py\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Model is 43 Mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "To be able to use this model, we need to know the index of the input and \n",
    "the index of the output. \n",
    "\n",
    "What's the output index for this model?\n",
    "\n",
    "* 3\n",
    "* 7\n",
    "* 13\n",
    "* 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_path='dino-dragon-model.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 13,\n",
       "  'shape': array([1, 1], dtype=int32),\n",
       "  'shape_signature': array([-1,  1], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preparing the image\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16354/1511810874.py:18: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  img = img.resize(target_size, Image.NEAREST)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Smaug_par_David_Demaret.jpg/1280px-Smaug_par_David_Demaret.jpg'\n",
    "img = download_image(url)\n",
    "img = prepare_image(img, (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Now we need to turn the image into numpy array and pre-process it. \n",
    "\n",
    "> Tip: Check the previous homework. What was the pre-processing \n",
    "> we did there?\n",
    "\n",
    "After the pre-processing, what's the value in the first pixel, the R channel?\n",
    "\n",
    "* 0.3353411\n",
    "* 0.5529412\n",
    "* 0.7458824\n",
    "* 0.9654902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5529412 , 0.31764707, 0.1764706 ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(img, dtype='float32')\n",
    "\n",
    "x /= 255\n",
    "\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 0.5529412"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Now let's apply this model to this image. What's the output of the model?\n",
    "\n",
    "* 0.17049132\n",
    "* 0.39009996\n",
    "* 0.60146114\n",
    "* 0.82448614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82448506]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "preds = interpreter.get_tensor(output_index)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 0.82448506"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the lambda code\n",
    "\n",
    "See [lambda_function.py](lambda_function.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker\n",
    "\n",
    "See [Dockerfile](Dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Download the base image `svizor42/zoomcamp-dino-dragon-lambda:v2`. You can easily make it by using [docker pull](https://docs.docker.com/engine/reference/commandline/pull/) command.\n",
    "\n",
    "So what's the size of this base image?\n",
    "\n",
    "* 139 Mb\n",
    "* 329 Mb\n",
    "* 639 Mb\n",
    "* 929 Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2: Pulling from svizor42/zoomcamp-dino-dragon-lambda\n",
      "Digest: sha256:46be01f7953cd48ebe526329ddf781d92019b9d44de4ecb67d11f56eaccf79cb\n",
      "Status: Image is up to date for svizor42/zoomcamp-dino-dragon-lambda:v2\n",
      "docker.io/svizor42/zoomcamp-dino-dragon-lambda:v2\n"
     ]
    }
   ],
   "source": [
    "!docker pull svizor42/zoomcamp-dino-dragon-lambda:v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svizor42/zoomcamp-dino-dragon-lambda                                                 v2                               20ef58b21a05   10 days ago      639MB\n"
     ]
    }
   ],
   "source": [
    "!docker images | grep svizor42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 639 Mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Now let's extend this docker image, install all the required libraries\n",
    "and add the code for lambda.\n",
    "\n",
    "You don't need to include the model in the image. It's already included. \n",
    "The name of the file with the model is `dino-vs-dragon-v2.tflite` and it's \n",
    "in the current workdir in the image (see the Dockerfile above for the \n",
    "reference).\n",
    "\n",
    "Now run the container locally.\n",
    "\n",
    "Score this image: https://upload.wikimedia.org/wikipedia/en/e/e9/GodzillaEncounterModel.jpg\n",
    "\n",
    "What's the output from the model?\n",
    "\n",
    "* 0.12\n",
    "* 0.32\n",
    "* 0.52\n",
    "* 0.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31950676441192627]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://localhost:8080/2015-03-31/functions/function/invocations'\n",
    "\n",
    "data = {'url': 'https://upload.wikimedia.org/wikipedia/en/e/e9/GodzillaEncounterModel.jpg'}\n",
    "\n",
    "result = requests.post(url, json=data).json()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 0.32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('vit-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6985ca9edadf785ffb39b5175c1ea3cc242afc0ecb9352eaccc1714ebb2bffce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
