# Machine Learning Vs. Rule-Based Systems

## Example: Email spam classification system
- Each training or test example is an email
- Want to prevent unsolicited or fraudulent emails
- All unwanted emails should go to a spam folder

## Building a Classifier
We need to build a classifier for spam
- Need to find patterns. What makes something spam?
	- E.g.: We can see everything from a certain domain is spam
	or
	- E.g.: We can see anything with tax review in the title is spam
- Can come up with rules like:
	- E.g.: If sender=promotions@ad.com then "spam"
		If title contains "tax review" then "spam"
		Else "good email"
- This works, until people start complaining about other unsolicited messages
	- E.g.: Fradulent prize emails asking for bank information
	- Can make new rule with a word like deposit
		- If body contains "deposit" then "spam"
- This also works, until someone needs a word like deposit.
	- Need to separate good emails from bad emails containing "deposit"
	- Add more rules under check for "deposit", like:
		- If sender domain is "test" then "spam"
		- If body>= 100 words then spam
- This becomes a never-ending process as spam and casual language changes over time
	- Becomes impossible to maintain a system like this

## ML
This is a situation ML is appropriate for.
- Steps for ML:
	1. Get data
	2. Define & calculate features
	3. Train and use the model

1. Getting Data
	- Email providers usually give users a spam folder automatically
	- Can use the data generated by user-marked spam to train the model

2. Define and calculate features
	- Can be very simple:
		- Length of title > 10 ? true/false
		- Length of body > 10 ? true/false
		- Sender "promotions.online.com" ? true/false
		- Sender "hpYOSKmL.test.com" ? true/false
		- Sender domain "test.com" ? true/false
		- Description contains "deposit" ? true/false
	- Recall that most of these features come from the rules we had
	- **Start with the rules and use these as features**
		- True/False emails are *binary*
		- Thus the above can be encoded as an array of 0's or 1's
	- Example email:
		![Example email](../images/one-hot-email.png)
		- This email would have an encoding of [1, 1, 0, 0, 1, 1]
			- Length of title > 10 ? **True** -> 1
			- Length of body > 10 ? **True** -> 1
			- Sender "promotions.online.com" ? **False** -> 0
			- And so on
		- For this email we use features = [1, 1, 0, 0, 1, 1], target = 1
			- Do this for every other email
				``` 		Features			Target
					[1, 1, 0, 0, 1, 1]			1
					[0, 0, 0, 1, 0, 1]			0
					[1, 1, 1, 0, 1, 0]			1
					[1, 0, 0, 0, 0, 1]			1
					[0, 0, 0, 1, 1, 0]			0
					[1, 0, 1, 0, 1, 1]			0
3. Train and Use Model
	- Take Features and Target
		- Use these to train and produce model. Decide on rule (e.g. >= 0.5)
			```
			Apply		Features 				Predictions		Final decision 
			(model)		(data)					(output)		(outcome)
						[1, 1, 0, 0, 1, 1]			0.8				Spam
						[0, 0, 0, 1, 0, 1]			0.6				S
			Model->		[1, 1, 1, 0, 1, 0]			0.1				Good
						[1, 0, 0, 0, 0, 1]			0.01			G
						[0, 0, 0, 1, 1, 0]			0.7				S
						[1, 0, 1, 0, 1, 1]			0.4				G
		- Everything S -> spam folder, G -> inbox

# Summary

## Rule-based
```
Data 	->	[				]
			|	Software	| -> Outcome (S/G)
Code	->	[				]
```
```
Data 			->	[		]
					|	ML	| -> Outcome (S/G)
Outcome	(S/G)	->	[		]
	In production: Data + Model = Outcome
```